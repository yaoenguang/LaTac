{
  "artifacts": [],
  "command": "my_main",
  "experiment": {
    "base_dir": "/home/LLM/\u684c\u9762/LT-main/src",
    "dependencies": [
      "munch==2.5.0",
      "numpy==1.21.5",
      "PyYAML==6.0",
      "sacred==0.7.5",
      "torch==1.12.1"
    ],
    "mainfile": "main.py",
    "name": "pymarl",
    "repositories": [],
    "sources": [
      [
        "main.py",
        "_sources/main_0e642570c09df44c2015d840c312bc14.py"
      ],
      [
        "utils/logging.py",
        "_sources/logging_ce9a261c391cbeae67129d3d806d06da.py"
      ]
    ]
  },
  "fail_trace": [
    "Traceback (most recent call last):\n",
    "  File \"/home/LLM/miniconda3/envs/pymarl2/lib/python3.7/site-packages/sacred/config/captured_function.py\", line 48, in captured_function\n    result = wrapped(*args, **kwargs)\n",
    "  File \"src/main.py\", line 40, in my_main\n    run_REGISTRY[_config['run']](_run, config, _log)\n",
    "  File \"/home/LLM/\u684c\u9762/LT-main/src/run/run.py\", line 61, in run\n    run_sequential(args=args, logger=logger)\n",
    "  File \"/home/LLM/\u684c\u9762/LT-main/src/run/run.py\", line 218, in run_sequential\n    learner.train(episode_sample, runner.t_env, episode)\n",
    "  File \"/home/LLM/\u684c\u9762/LT-main/src/learners/t_learner.py\", line 153, in train\n    moco_loss_1, comm_loss_1 = self.tactic_dis_forward(batch, t, tactic_outs.clone().detach(), mha_out.clone().detach())\n",
    "  File \"/home/LLM/\u684c\u9762/LT-main/src/learners/t_learner.py\", line 107, in tactic_dis_forward\n    drop_tactic, drop_mha = self.mac.forward(batch, t=t, test_mode=True, drop_prob=p, train_drop=True)\n",
    "  File \"/home/LLM/\u684c\u9762/LT-main/src/controllers/tactic_controller.py\", line 83, in forward\n    agent_inputs, drop_inputs = self._build_inputs(ep_batch, t)  # agent_inputs 48*192\n",
    "  File \"/home/LLM/\u684c\u9762/LT-main/src/controllers/tactic_controller.py\", line 175, in _build_inputs\n    inputs = th.cat([x.reshape(bs * self.n_agents, -1) for x in inputs], dim=1)\n",
    "RuntimeError: CUDA out of memory. Tried to allocate 2.00 MiB (GPU 1; 23.64 GiB total capacity; 6.97 GiB already allocated; 1.50 MiB free; 7.09 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n"
  ],
  "heartbeat": "2025-01-10T03:42:55.622692",
  "host": {
    "ENV": {},
    "cpu": "Intel(R) Xeon(R) Silver 4314 CPU @ 2.40GHz",
    "gpus": {
      "driver_version": "550.120",
      "gpus": [
        {
          "model": "NVIDIA GeForce RTX 4090",
          "persistence_mode": false,
          "total_memory": 24564
        },
        {
          "model": "NVIDIA GeForce RTX 4090",
          "persistence_mode": false,
          "total_memory": 24564
        }
      ]
    },
    "hostname": "llm",
    "os": [
      "Linux",
      "Linux-6.8.0-51-generic-x86_64-with-debian-bookworm-sid"
    ],
    "python_version": "3.7.16"
  },
  "meta": {
    "command": "my_main",
    "options": {
      "--beat_interval": null,
      "--capture": null,
      "--comment": null,
      "--debug": false,
      "--enforce_clean": false,
      "--file_storage": null,
      "--force": false,
      "--help": false,
      "--loglevel": null,
      "--mongo_db": null,
      "--name": null,
      "--pdb": false,
      "--print_config": false,
      "--priority": null,
      "--queue": false,
      "--sql": null,
      "--tiny_db": null,
      "--unobserved": false,
      "COMMAND": null,
      "UPDATE": [
        "env_args.map_name=6h_vs_8z"
      ],
      "help": false,
      "with": true
    }
  },
  "resources": [],
  "result": null,
  "start_time": "2025-01-10T03:18:14.198572",
  "status": "FAILED",
  "stop_time": "2025-01-10T03:42:55.661154"
}